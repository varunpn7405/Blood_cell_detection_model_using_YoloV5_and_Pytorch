{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":316},"id":"D3iUzGzVFGLa","outputId":"77978861-f402-4217-9738-60bda4bc1e9e","executionInfo":{"status":"ok","timestamp":1721191009359,"user_tz":-330,"elapsed":15763,"user":{"displayName":"varun pn","userId":"07030328907390470712"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: gdown in /usr/local/lib/python3.10/dist-packages (5.1.0)\n","Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from gdown) (4.12.3)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from gdown) (3.15.4)\n","Requirement already satisfied: requests[socks] in /usr/local/lib/python3.10/dist-packages (from gdown) (2.32.3)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from gdown) (4.66.4)\n","Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->gdown) (2.5)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (2024.7.4)\n","Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (1.7.1)\n"]},{"output_type":"stream","name":"stderr","text":["Downloading...\n","From: https://drive.google.com/uc?id=1nYSJSXOZhywPzWHbq3csuWvTP6UPc7DR\n","To: /content/BCCD.v4-416x416_aug.yolov5pytorch.zip\n","100%|██████████| 13.3M/13.3M [00:00<00:00, 161MB/s]\n"]},{"output_type":"execute_result","data":{"text/plain":["'./BCCD.v4-416x416_aug.yolov5pytorch.zip'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":1}],"source":["!pip install gdown\n","import gdown\n","\n","# URL to the Google Drive file\n","drive_link = 'https://drive.google.com/uc?id=1nYSJSXOZhywPzWHbq3csuWvTP6UPc7DR'\n","# Download the file\n","output_path = './'\n","gdown.download(drive_link, output_path, quiet=False)"]},{"cell_type":"code","source":["import zipfile\n","import os\n","\n","def unzip_folder(zip_path, extract_to):\n","    \"\"\"\n","    Unzips the specified zip file into the specified directory.\n","\n","    :param zip_path: Path to the zip file\n","    :param extract_to: Directory to extract the contents to\n","    \"\"\"\n","    # Ensure the extract_to directory exists\n","    if not os.path.exists(extract_to):\n","        os.makedirs(extract_to)\n","\n","    # Open the zip file\n","    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n","        # Extract all contents\n","        zip_ref.extractall(extract_to)\n","        print(f\"Extracted all files to {extract_to}\")\n","\n","# Example usage\n","zip_path = '/content/BCCD.v4-416x416_aug.yolov5pytorch.zip'\n","extract_to = './'\n","unzip_folder(zip_path, extract_to)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EOxSXCgF8jed","executionInfo":{"status":"ok","timestamp":1721191010074,"user_tz":-330,"elapsed":723,"user":{"displayName":"varun pn","userId":"07030328907390470712"}},"outputId":"5bd18be8-68e7-4104-8821-aca2107d57e1"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Extracted all files to ./\n"]}]},{"cell_type":"code","execution_count":3,"metadata":{"id":"L49gYzZtEivD","executionInfo":{"status":"ok","timestamp":1721191010074,"user_tz":-330,"elapsed":10,"user":{"displayName":"varun pn","userId":"07030328907390470712"}}},"outputs":[],"source":["# import os,shutil\n","\n","# cPath=os.getcwd()\n","# inputPar=os.path.join(cPath,\"data\")\n","# outPar=os.path.join(cPath,\"Dataset\")\n","\n","# def copyFiles(fldr,files,category,inputChild):\n","\n","#     outSub=os.path.join(outPar,category,fldr)\n","#     os.makedirs(outSub,exist_ok=True)\n","\n","#     for fl in files:\n","#         finput=os.path.join(inputChild,fl)\n","#         fout=os.path.join(outSub,fl)\n","#         shutil.copy(finput,fout)\n","\n","# for folder in os.listdir(inputPar):\n","#     inputChild=os.path.join(inputPar,folder)\n","#     files=os.listdir(inputChild)\n","\n","#     trainLen=int(len(files)*0.7)\n","#     valLen=int(len(files)*0.2)\n","#     testLen=int(len(files)*0.1)\n","#     trainset=files[:trainLen]\n","#     valSet=files[trainLen:trainLen+valLen]\n","#     testSet=files[trainLen+valLen:]\n","\n","#     copyFiles(folder,trainset,\"train\",inputChild)\n","#     copyFiles(folder,valSet,\"valid\",inputChild)\n","#     copyFiles(folder,testSet,\"test\",inputChild)"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BRPrPn3gQ_Ax","outputId":"2e4cfc3b-d938-4d02-c0e9-2dd3995f2a53","executionInfo":{"status":"ok","timestamp":1721191010074,"user_tz":-330,"elapsed":9,"user":{"displayName":"varun pn","userId":"07030328907390470712"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["process Completed in !! 0.2411813735961914\n"]}],"source":["import os\n","import shutil\n","from concurrent.futures import ThreadPoolExecutor\n","import time\n","\n","startTime=time.time()\n","def copy_files(src_dir, dst_dir):\n","    \"\"\"Copy files from src_dir to dst_dir.\"\"\"\n","    os.makedirs(dst_dir, exist_ok=True)\n","    for file in os.listdir(src_dir):\n","        shutil.copy(os.path.join(src_dir, file), os.path.join(dst_dir, file))\n","\n","def process_folder(inputPar, outPar, folder):\n","    \"\"\"Process 'images' and 'labels' subfolders within the given folder.\"\"\"\n","\n","    if folder in [\"train\", \"valid\", \"test\"]:\n","      inputChild = os.path.join(inputPar, folder)\n","\n","      for subfldr in [\"images\", \"labels\"]:\n","          inputSubChild = os.path.join(inputChild, subfldr)\n","          outChild = os.path.join(outPar, subfldr, folder)\n","\n","          if os.path.exists(inputSubChild):\n","              copy_files(inputSubChild, outChild)\n","\n","def main():\n","    cPath = os.getcwd()\n","    inputPar = cPath\n","    outPar = os.path.join(cPath, \"Dataset\")\n","\n","    folders = [\"train\", \"valid\", \"test\"]\n","\n","    with ThreadPoolExecutor() as executor:\n","        executor.map(lambda folder: process_folder(inputPar, outPar, folder), folders)\n","\n","if __name__ == \"__main__\":\n","    main()\n","\n","endTime=time.time()\n","\n","print(\"process Completed in !!\",endTime-startTime)"]},{"cell_type":"code","execution_count":17,"metadata":{"id":"X0QwxzR_Ojma","executionInfo":{"status":"ok","timestamp":1721191393599,"user_tz":-330,"elapsed":421,"user":{"displayName":"varun pn","userId":"07030328907390470712"}}},"outputs":[],"source":["import yaml\n","\n","# Define the data configuration\n","data_config = {\n","    'train': '/content/Dataset/images/train',\n","    'val': '/content/Dataset/images/valid',\n","    'nc': 3,  # number of classes\n","    'names': ['Platelets', 'RBC', 'WBC']\n","}\n","\n","# Write the configuration to a YAML file\n","with open('custom_dataset.yaml', 'w') as file:\n","    yaml.dump(data_config, file)"]},{"cell_type":"code","source":["import ast\n","\n","with open(r\"/content/custom_dataset.yaml\") as f:\n","    dataYaml=f.readlines()\n","\n","num_cls=0\n","for line in dataYaml:\n","\n","    if line.startswith(\"nc:\"):\n","        num_classes=int(line.split(\"nc:\")[-1])\n","        num_cls=num_classes\n","        break\n","\n","with open(\"classes.txt\",\"w\") as f:\n","\n","    for cls in dataYaml[1:num_cls+1]:\n","        f.write(cls.lstrip(\"- \"))"],"metadata":{"id":"qxgCbBSYDYSf","executionInfo":{"status":"ok","timestamp":1721191010074,"user_tz":-330,"elapsed":7,"user":{"displayName":"varun pn","userId":"07030328907390470712"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["with open(\"classes.txt\") as f:\n","  classes=f.readlines()\n","\n","classes=[i.rstrip() for i in classes]\n","print(classes)"],"metadata":{"id":"CczHJ242EExX","executionInfo":{"status":"ok","timestamp":1721191010075,"user_tz":-330,"elapsed":8,"user":{"displayName":"varun pn","userId":"07030328907390470712"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"57af1976-95d2-4b25-8cfb-d260c9c9cbe6"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["['Platelets', 'RBC', 'WBC']\n"]}]},{"cell_type":"code","execution_count":8,"metadata":{"id":"bakmARZVhwSA","executionInfo":{"status":"ok","timestamp":1721191010075,"user_tz":-330,"elapsed":7,"user":{"displayName":"varun pn","userId":"07030328907390470712"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"3284866c-b616-4544-eb7f-b7ed88f0b28b"},"outputs":[{"output_type":"stream","name":"stdout","text":["fatal: destination path 'yolov5' already exists and is not an empty directory.\n","/content/yolov5\n"]}],"source":["!git clone https://github.com/ultralytics/yolov5.git\n","%cd yolov5"]},{"cell_type":"code","source":["# !pip install -r requirements.txt\n"],"metadata":{"id":"KCKCQzlU-Blf","executionInfo":{"status":"ok","timestamp":1721191010075,"user_tz":-330,"elapsed":5,"user":{"displayName":"varun pn","userId":"07030328907390470712"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["!python train.py --img 640 --batch 16 --epochs 25 --data \"/content/yolov5/custom_dataset.yaml\" --weights yolov5s.pt --cache"],"metadata":{"id":"2-ycdw9j-Bo_","executionInfo":{"status":"ok","timestamp":1721192197930,"user_tz":-330,"elapsed":476358,"user":{"displayName":"varun pn","userId":"07030328907390470712"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"6a52051d-8a67-4542-f88b-8b3652ee70b0"},"execution_count":19,"outputs":[{"output_type":"stream","name":"stdout","text":["2024-07-17 04:48:48.995195: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2024-07-17 04:48:48.995250: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2024-07-17 04:48:48.997186: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","\u001b[34m\u001b[1mtrain: \u001b[0mweights=yolov5s.pt, cfg=, data=/content/yolov5/custom_dataset.yaml, hyp=data/hyps/hyp.scratch-low.yaml, epochs=25, batch_size=16, imgsz=640, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, evolve_population=data/hyps, resume_evolve=None, bucket=, cache=ram, image_weights=False, device=, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=runs/train, name=exp, exist_ok=False, quad=False, cos_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, seed=0, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest, ndjson_console=False, ndjson_file=False\n","\u001b[34m\u001b[1mgithub: \u001b[0mup to date with https://github.com/ultralytics/yolov5 ✅\n","YOLOv5 🚀 v7.0-342-g12be4996 Python-3.10.12 torch-2.3.0+cu121 CUDA:0 (Tesla T4, 15102MiB)\n","\n","\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n","\u001b[34m\u001b[1mComet: \u001b[0mrun 'pip install comet_ml' to automatically track and visualize YOLOv5 🚀 runs in Comet\n","\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\n","Overriding model.yaml nc=80 with nc=3\n","\n","                 from  n    params  module                                  arguments                     \n","  0                -1  1      3520  models.common.Conv                      [3, 32, 6, 2, 2]              \n","  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n","  2                -1  1     18816  models.common.C3                        [64, 64, 1]                   \n","  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n","  4                -1  2    115712  models.common.C3                        [128, 128, 2]                 \n","  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n","  6                -1  3    625152  models.common.C3                        [256, 256, 3]                 \n","  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n","  8                -1  1   1182720  models.common.C3                        [512, 512, 1]                 \n","  9                -1  1    656896  models.common.SPPF                      [512, 512, 5]                 \n"," 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n"," 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n"," 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n"," 13                -1  1    361984  models.common.C3                        [512, 256, 1, False]          \n"," 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n"," 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n"," 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n"," 17                -1  1     90880  models.common.C3                        [256, 128, 1, False]          \n"," 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n"," 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n"," 20                -1  1    296448  models.common.C3                        [256, 256, 1, False]          \n"," 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n"," 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n"," 23                -1  1   1182720  models.common.C3                        [512, 512, 1, False]          \n"," 24      [17, 20, 23]  1     21576  models.yolo.Detect                      [3, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [128, 256, 512]]\n","Model summary: 214 layers, 7027720 parameters, 7027720 gradients, 16.0 GFLOPs\n","\n","Transferred 343/349 items from yolov5s.pt\n","\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n","\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01) with parameter groups 57 weight(decay=0.0), 60 weight(decay=0.0005), 60 bias\n","\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n","\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/Dataset/labels/train.cache... 765 images, 0 backgrounds, 0 corrupt: 100% 765/765 [00:00<?, ?it/s]\n","\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (0.9GB ram): 100% 765/765 [00:02<00:00, 300.05it/s]\n","/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n","  self.pid = os.fork()\n","\u001b[34m\u001b[1mval: \u001b[0mScanning /content/Dataset/labels/valid.cache... 73 images, 0 backgrounds, 0 corrupt: 100% 73/73 [00:00<?, ?it/s]\n","\u001b[34m\u001b[1mval: \u001b[0mCaching images (0.1GB ram): 100% 73/73 [00:00<00:00, 91.63it/s]\n","\n","\u001b[34m\u001b[1mAutoAnchor: \u001b[0m5.30 anchors/target, 0.999 Best Possible Recall (BPR). Current anchors are a good fit to dataset ✅\n","Plotting labels to runs/train/exp4/labels.jpg... \n","Image sizes 640 train, 640 val\n","Using 2 dataloader workers\n","Logging results to \u001b[1mruns/train/exp4\u001b[0m\n","Starting training for 25 epochs...\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","       0/24      3.67G    0.09234     0.1454    0.03203        315        640: 100% 48/48 [00:21<00:00,  2.25it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 3/3 [00:02<00:00,  1.45it/s]\n","                   all         73        967     0.0675      0.227     0.0533     0.0152\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","       1/24      4.48G    0.06174     0.1435    0.01527        299        640: 100% 48/48 [00:14<00:00,  3.36it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 3/3 [00:02<00:00,  1.30it/s]\n","                   all         73        967      0.486      0.559      0.561      0.163\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","       2/24      4.48G     0.0579     0.1379      0.012        241        640: 100% 48/48 [00:16<00:00,  2.89it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 3/3 [00:02<00:00,  1.47it/s]\n","                   all         73        967      0.446        0.6      0.524      0.189\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","       3/24      4.48G    0.05179     0.1336   0.008839        317        640: 100% 48/48 [00:13<00:00,  3.60it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 3/3 [00:01<00:00,  1.66it/s]\n","                   all         73        967      0.429      0.768      0.559      0.249\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","       4/24      4.48G    0.04602     0.1338   0.005688        271        640: 100% 48/48 [00:13<00:00,  3.62it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 3/3 [00:01<00:00,  1.97it/s]\n","                   all         73        967        0.5      0.738      0.562       0.31\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","       5/24      4.48G    0.04299     0.1286   0.004264        233        640: 100% 48/48 [00:13<00:00,  3.51it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 3/3 [00:01<00:00,  2.17it/s]\n","                   all         73        967      0.763      0.798      0.826      0.501\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","       6/24      4.48G    0.03903     0.1295   0.003569        237        640: 100% 48/48 [00:14<00:00,  3.41it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 3/3 [00:00<00:00,  3.03it/s]\n","                   all         73        967      0.751      0.892      0.859      0.507\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","       7/24      4.48G    0.03785     0.1298   0.003085        228        640: 100% 48/48 [00:15<00:00,  3.18it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 3/3 [00:01<00:00,  2.79it/s]\n","                   all         73        967      0.797       0.88      0.876      0.507\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","       8/24      4.48G    0.03624      0.131   0.002566        248        640: 100% 48/48 [00:17<00:00,  2.72it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 3/3 [00:00<00:00,  3.17it/s]\n","                   all         73        967      0.819      0.866      0.884      0.534\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","       9/24      4.48G    0.03456     0.1255   0.002384        249        640: 100% 48/48 [00:15<00:00,  3.08it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 3/3 [00:00<00:00,  3.21it/s]\n","                   all         73        967      0.848       0.89      0.911      0.581\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      10/24      4.48G    0.03355     0.1262   0.002109        302        640: 100% 48/48 [00:15<00:00,  3.01it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 3/3 [00:01<00:00,  2.85it/s]\n","                   all         73        967      0.832       0.89      0.911      0.566\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      11/24      4.48G    0.03329     0.1229   0.001976        195        640: 100% 48/48 [00:15<00:00,  3.03it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 3/3 [00:01<00:00,  1.63it/s]\n","                   all         73        967      0.819      0.909      0.922      0.587\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      12/24      4.48G     0.0315     0.1249    0.00193        253        640: 100% 48/48 [00:17<00:00,  2.74it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 3/3 [00:01<00:00,  2.62it/s]\n","                   all         73        967      0.808      0.899      0.904      0.585\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      13/24      4.48G    0.03162     0.1295   0.001759        274        640: 100% 48/48 [00:14<00:00,  3.24it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 3/3 [00:02<00:00,  1.43it/s]\n","                   all         73        967      0.816      0.906      0.906      0.569\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      14/24      4.48G    0.03018     0.1248   0.001719        298        640: 100% 48/48 [00:13<00:00,  3.60it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 3/3 [00:02<00:00,  1.45it/s]\n","                   all         73        967      0.845       0.91      0.913      0.619\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      15/24      4.48G    0.02963     0.1242   0.001582        313        640: 100% 48/48 [00:13<00:00,  3.58it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 3/3 [00:01<00:00,  1.87it/s]\n","                   all         73        967      0.848      0.895      0.913       0.61\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      16/24      4.48G    0.02936     0.1202   0.001331        248        640: 100% 48/48 [00:14<00:00,  3.39it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 3/3 [00:01<00:00,  2.28it/s]\n","                   all         73        967      0.855      0.902      0.919      0.618\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      17/24      4.48G    0.02899     0.1238   0.001326        267        640: 100% 48/48 [00:14<00:00,  3.24it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 3/3 [00:00<00:00,  3.20it/s]\n","                   all         73        967      0.839       0.91      0.921      0.624\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      18/24      4.48G    0.02834     0.1218   0.001295        265        640: 100% 48/48 [00:18<00:00,  2.64it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 3/3 [00:00<00:00,  3.01it/s]\n","                   all         73        967      0.888      0.876      0.922      0.631\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      19/24      4.48G    0.02784     0.1194   0.001203        304        640: 100% 48/48 [00:15<00:00,  3.05it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 3/3 [00:00<00:00,  3.07it/s]\n","                   all         73        967      0.833      0.894       0.91      0.628\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      20/24      4.48G    0.02758     0.1174    0.00117        268        640: 100% 48/48 [00:16<00:00,  2.98it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 3/3 [00:00<00:00,  3.19it/s]\n","                   all         73        967      0.863      0.886      0.914      0.626\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      21/24      4.48G    0.02667     0.1153   0.001112        287        640: 100% 48/48 [00:16<00:00,  2.83it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 3/3 [00:02<00:00,  1.49it/s]\n","                   all         73        967      0.867      0.851      0.908      0.626\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      22/24      4.48G    0.02673     0.1209   0.001057        219        640: 100% 48/48 [00:16<00:00,  2.88it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 3/3 [00:00<00:00,  3.02it/s]\n","                   all         73        967      0.859      0.882      0.911      0.638\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      23/24      4.48G     0.0263     0.1159  0.0009694        262        640: 100% 48/48 [00:15<00:00,  3.09it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 3/3 [00:01<00:00,  2.60it/s]\n","                   all         73        967      0.874      0.878      0.919      0.635\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      24/24      4.48G    0.02622      0.115  0.0009161        226        640: 100% 48/48 [00:14<00:00,  3.41it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 3/3 [00:01<00:00,  1.53it/s]\n","                   all         73        967      0.853      0.902       0.92      0.627\n","\n","25 epochs completed in 0.122 hours.\n","Optimizer stripped from runs/train/exp4/weights/last.pt, 14.5MB\n","Optimizer stripped from runs/train/exp4/weights/best.pt, 14.5MB\n","\n","Validating runs/train/exp4/weights/best.pt...\n","Fusing layers... \n","Model summary: 157 layers, 7018216 parameters, 0 gradients, 15.8 GFLOPs\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 3/3 [00:02<00:00,  1.04it/s]\n","                   all         73        967      0.859      0.882      0.911      0.638\n","             Platelets         73         76       0.79      0.895      0.876      0.497\n","                   RBC         73        819       0.82      0.752      0.882      0.624\n","                   WBC         73         72      0.968          1      0.976      0.794\n","Results saved to \u001b[1mruns/train/exp4\u001b[0m\n"]}]},{"cell_type":"code","execution_count":11,"metadata":{"id":"BT63q1jmJVSR","executionInfo":{"status":"ok","timestamp":1721191024816,"user_tz":-330,"elapsed":26,"user":{"displayName":"varun pn","userId":"07030328907390470712"}},"collapsed":true},"outputs":[],"source":["# #------------------ pretrained model ---------------------\n","# drive_link = 'https://drive.google.com/uc?id=1PHlMNPKfN6WIChYmzJGjMGRez_RQaXeh'\n","# # Download the file\n","# output_path = './'\n","# gdown.download(drive_link, output_path, quiet=False)"]},{"cell_type":"code","execution_count":12,"metadata":{"id":"AEwr1JtmQ_D1","executionInfo":{"status":"ok","timestamp":1721191024816,"user_tz":-330,"elapsed":25,"user":{"displayName":"varun pn","userId":"07030328907390470712"}},"collapsed":true},"outputs":[],"source":["# !yolo task=detect mode=train model=best.pt data=/content/data.yaml epochs=5 plots=True"]},{"cell_type":"code","source":["import torch\n","import cv2\n","import numpy as np\n","from pathlib import Path\n","\n","# Load the YOLOv5 model\n","model_path = '/content/yolov5/runs/train/exp4/weights/best.pt'  # Replace with your model path\n","model = torch.hub.load('ultralytics/yolov5', 'custom', path=model_path)\n","\n","# Load an image\n","img_path = '/content/Dataset/images/test/BloodImage_00337_jpg.rf.b6cb228440b9158cafec01a0351e3aad.jpg'  # Replace with your image path\n","img = cv2.imread(img_path)\n","\n","# Convert the image to RGB (YOLOv5 expects RGB images)\n","img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n","\n","# Perform inference\n","results = model(img_rgb)\n","\n","# Print results\n","results.print()  # Print results to the console\n","\n","# Extract bounding boxes and labels\n","bbox_tensor = results.xyxy[0].cpu()  # Move the tensor to CPU\n","bbox_array = bbox_tensor.numpy()  # Convert to NumPy array\n","\n","for bbox in bbox_array:\n","    x1, y1, x2, y2, conf, cls = bbox\n","    label = model.names[int(cls)]\n","    conf = f'{conf:.2f}'\n","\n","    # Draw bounding box\n","    cv2.rectangle(img, (int(x1), int(y1)), (int(x2), int(y2)), (0, 255, 0), 2)\n","    cv2.putText(img, f'{label} {conf}', (int(x1), int(y1) - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n","\n","# Save the output image\n","output_path = '/content/Untitled Folder/output_image.jpg'  # Replace with your desired output path\n","cv2.imwrite(output_path, img)\n","\n","\n"],"metadata":{"id":"w2izjBiA_QlK","executionInfo":{"status":"ok","timestamp":1721193161738,"user_tz":-330,"elapsed":1080,"user":{"displayName":"varun pn","userId":"07030328907390470712"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"f71d4e3f-258b-4e46-ab95-4cc0821878be"},"execution_count":27,"outputs":[{"output_type":"stream","name":"stderr","text":["Using cache found in /root/.cache/torch/hub/ultralytics_yolov5_master\n","YOLOv5 🚀 v7.0-342-g12be4996 Python-3.10.12 torch-2.3.0+cu121 CUDA:0 (Tesla T4, 15102MiB)\n","\n","Fusing layers... \n","Model summary: 157 layers, 7018216 parameters, 0 gradients, 15.8 GFLOPs\n","Adding AutoShape... \n","image 1/1: 416x416 29 RBCs, 1 WBC\n","Speed: 2.2ms pre-process, 7.0ms inference, 6.0ms NMS per image at shape (1, 3, 640, 640)\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":27}]},{"cell_type":"code","source":["import torch\n","import cv2\n","import numpy as np\n","from pathlib import Path\n","from matplotlib import pyplot as plt\n","\n","# Define our imshow function\n","def imshow(title = \"Image\", image = None, size = 10):\n","    w, h = image.shape[0], image.shape[1]\n","    aspect_ratio = w/h\n","    plt.figure(figsize=(size * aspect_ratio,size))\n","    plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n","    plt.title(title)\n","    plt.show()\n","\n","# Load the YOLOv5 model\n","model_path = '/content/yolov5/runs/train/exp4/weights/best.pt'  # Replace with your model path\n","model = torch.hub.load('ultralytics/yolov5', 'custom', path=model_path)\n","\n","# Load an image\n","img_path = '/content/Dataset/images/test/BloodImage_00090_jpg.rf.cdbf8f6ed3b93fa902a0bc991132cb40.jpg'  # Replace with your image path\n","img = cv2.imread(img_path)\n","\n","# Convert the image to RGB (YOLOv5 expects RGB images)\n","img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n","\n","# Perform inference\n","results = model(img_rgb)\n","\n","# Print results\n","results.print()  # Print results to the console\n","\n","# Extract bounding boxes and labels\n","bbox_tensor = results.xyxy[0].cpu()  # Move the tensor to CPU\n","bbox_array = bbox_tensor.numpy()  # Convert to NumPy array\n","\n","# Non-Max Suppression parameters (if you want to customize)\n","iou_threshold = 0.5  # Intersection over Union threshold\n","confidence_threshold = 0.25  # Confidence score threshold\n","\n","# Apply NMS\n","filtered_boxes = []\n","for bbox in bbox_array:\n","    if bbox[4] >= confidence_threshold:\n","        filtered_boxes.append(bbox)\n","\n","filtered_boxes = np.array(filtered_boxes)\n","\n","# Convert to the format required by cv2.dnn.NMSBoxes\n","boxes = [[int(box[0]), int(box[1]), int(box[2] - box[0]), int(box[3] - box[1])] for box in filtered_boxes]\n","scores = [box[4] for box in filtered_boxes]\n","\n","# Apply NMS\n","indices = cv2.dnn.NMSBoxes(\n","    bboxes=boxes,\n","    scores=scores,\n","    score_threshold=confidence_threshold,\n","    nms_threshold=iou_threshold\n",")\n","\n","# Draw bounding boxes and labels\n","for i in indices:\n","\n","    x1, y1, w, h = boxes[i]\n","    x2, y2 = x1 + w, y1 + h\n","    conf, cls = filtered_boxes[i][4], filtered_boxes[i][5]\n","    label = model.names[int(cls)]\n","    conf = f'{conf:.2f}'\n","\n","    # Draw bounding box\n","    cv2.rectangle(img, (x1, y1), (x2, y2), (0, 255, 0), 2)\n","    cv2.putText(img, f'{label} {conf}', (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n","\n","\n","# Save the output image\n","output_path = '/content/Untitled Folder/output_image_2.jpg'  # Replace with your desired output path\n","cv2.imwrite(output_path, img)\n","imshow(\"image\",img)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-hqQOW1SHkiI","executionInfo":{"status":"ok","timestamp":1721193956073,"user_tz":-330,"elapsed":1103,"user":{"displayName":"varun pn","userId":"07030328907390470712"}},"outputId":"661568ed-fd85-46fa-b052-e797671c4185"},"execution_count":36,"outputs":[{"output_type":"stream","name":"stderr","text":["Using cache found in /root/.cache/torch/hub/ultralytics_yolov5_master\n","YOLOv5 🚀 v7.0-342-g12be4996 Python-3.10.12 torch-2.3.0+cu121 CUDA:0 (Tesla T4, 15102MiB)\n","\n","Fusing layers... \n","Model summary: 157 layers, 7018216 parameters, 0 gradients, 15.8 GFLOPs\n","Adding AutoShape... \n","image 1/1: 416x416 3 Plateletss, 26 RBCs, 1 WBC\n","Speed: 2.1ms pre-process, 6.5ms inference, 6.5ms NMS per image at shape (1, 3, 640, 640)\n"]},{"output_type":"stream","name":"stdout","text":["yes\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"QrXwkqhmH3BO","executionInfo":{"status":"ok","timestamp":1721193790541,"user_tz":-330,"elapsed":426,"user":{"displayName":"varun pn","userId":"07030328907390470712"}}},"execution_count":33,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"cSIEbXtzH3FV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"4boEnRNPH3JZ"},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}